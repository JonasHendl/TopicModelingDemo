{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/JonasHendl/TopicModelingDemo.git  # clone\n",
    "%cd TopicModelingDemo\n",
    "%pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint: You can execute cells with \"strg\" + \"enter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import List\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import datetime as dt\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/demo_reviews.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_reviews = 2000 #we limit the number of data points for faster processing. If you are using your own GPU feel free to set this to a higher number. \n",
    "reviews_df = data[\"reviews_df\"][:number_of_reviews]\n",
    "docs = reviews_df[\"text\"][:number_of_reviews]\n",
    "embeddings = data[\"embeddings\"][:number_of_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_examples_you_want_to_view = 10\n",
    "\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    # This will display the sample with full column texts\n",
    "    # display(reviews_df.sample(n=number_of_examples_you_want_to_view, random_state=random_seed))\n",
    "    display(reviews_df.sample(n=number_of_examples_you_want_to_view))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function new_model initializes all sub-modules with relevant parameters. I already chose some parameters for your, so you do not need to do anything right now. Later, you can experiment with different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def new_model(\n",
    "        n_neighbors: int = 15,\n",
    "        n_components: int = 5,\n",
    "        min_dist: float = 0.0,\n",
    "        metric_umap: str = \"cosine\",\n",
    "        min_cluster_size: int = 20,\n",
    "        metric_hdbscan: str = \"euclidean\",\n",
    "        cluster_selection_method: str = \"leaf\",  # eom\n",
    "        cluster_selection_epsilon: float = 0.2,\n",
    "        prediction_data: bool = True,\n",
    "        alpha: float = 1.0,\n",
    "        max_features: int = None,\n",
    "        min_samples: int = 5,\n",
    "        seed_topic_list: List[List[str]] = None,\n",
    "        seed: int = 42,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create a new BERTopic model configured with various parameters for UMAP, HDBSCAN, and vectorization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_neighbors : int, optional, default=15\n",
    "            Number of neighbors to consider for UMAP.\n",
    "        n_components : int, optional, default=5\n",
    "            Number of components for dimensionality reduction in UMAP.\n",
    "        min_dist : float, optional, default=0.0\n",
    "            Minimum distance between points in the low-dimensional representation in UMAP.\n",
    "        metric_umap : str, optional, default='cosine'\n",
    "            Metric to use for UMAP.\n",
    "        min_cluster_size : int, optional, default=10\n",
    "            Minimum cluster size for HDBSCAN.\n",
    "        metric_hdbscan : str, optional, default='euclidean'\n",
    "            Metric to use for HDBSCAN clustering.\n",
    "        cluster_selection_method : str, optional, default='eom'\n",
    "            Method for selecting clusters in HDBSCAN.\n",
    "        cluster_selection_epsilon : float, optional, default=0.1\n",
    "            Cluster selection epsilon parameter for HDBSCAN.\n",
    "            Larger Values: Setting a larger cluster_selection_epsilon can result in fewer, larger clusters. This is because more points will be included in clusters, as the algorithm is less strict about the density required to form a cluster.\n",
    "            Smaller Values: A smaller cluster_selection_epsilon can lead to more, smaller clusters, as it requires higher density (closer points) to consider points as part of the same cluster.\n",
    "            HDBSCAN does not require the specification of an epsilon value upfront, as it builds a hierarchy of clusters based on varying epsilons. However, the cluster_selection_epsilon parameter is used during the cluster selection process after this hierarchy is built. Hereâ€™s how it works:\n",
    "\n",
    "            Hierarchy Creation: HDBSCAN first creates a hierarchy of clusters by varying the density (distance) threshold, effectively exploring a range of epsilon values.\n",
    "            Cluster Selection: After the hierarchy is built, HDBSCAN needs to decide which clusters in this hierarchy to select as the final clusters. This is where cluster_selection_epsilon comes into play.\n",
    "            Thresholding: The cluster_selection_epsilon parameter sets a minimum distance threshold. Clusters formed below this threshold are considered too sparsely connected to be valid and are merged with their nearest neighbor clusters.\n",
    "            Stability-Based Selection: HDBSCAN selects clusters based on their stability across the hierarchy. The cluster_selection_epsilon parameter adds an additional constraint to this process by not allowing the selection of clusters that fall below the specified distance threshold.\n",
    "\n",
    "        prediction_data : bool, optional, default=True\n",
    "            Whether to generate prediction data in HDBSCAN.\n",
    "        alpha : float, optional, default=1.0\n",
    "            Alpha parameter for HDBSCAN.\n",
    "        max_features : int, optional, default=None\n",
    "            Maximum number of features for CountVectorizer.\n",
    "        min_samples: int, optional, default=5\n",
    "            Similar to min_cluster_size. Indepth documentation at HDBSCAN repo.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            This method modifies the internal state of the ClusteringModel instance but does not return anything.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This method modifies the internal state of the ClusteringModel instance.\n",
    "        \"\"\"\n",
    "\n",
    "        umap_model = UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            n_components=n_components,\n",
    "            min_dist=min_dist,\n",
    "            metric=metric_umap,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        hdbscan_model = HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            metric=metric_hdbscan,\n",
    "            cluster_selection_method=cluster_selection_method,\n",
    "            prediction_data=prediction_data,\n",
    "            cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "            alpha=alpha,\n",
    "            min_samples=min_samples,\n",
    "        )\n",
    "\n",
    "        vectorizer_model = CountVectorizer(\n",
    "            stop_words=\"english\", max_features=max_features, ngram_range=(1, 3)\n",
    "        )\n",
    "\n",
    "        ctfidf_model = ClassTfidfTransformer(\n",
    "            bm25_weighting=True, reduce_frequent_words=True\n",
    "        )\n",
    "\n",
    "        model = BERTopic(\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            vectorizer_model=vectorizer_model,\n",
    "            ctfidf_model=ctfidf_model,\n",
    "            calculate_probabilities=True,\n",
    "            seed_topic_list=seed_topic_list,\n",
    "            verbose=True\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model\n",
    "topic_model = new_model()\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings) #we initialize our model with pre-computed embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at a scatter plot of the reviews. The same color signifies the same class. You can hover to look at the reviews. Keep in mind that you only see a small fraction of the data (to save your browser from crashing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_answers_visulaized = 0.10\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=data[\"2D_embeddings\"][:number_of_reviews], sample=fraction_of_answers_visulaized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_number = 5\n",
    "topic_model.get_topic(topic_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs(topic=topic_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy() #shows hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOWER the minimum number of messages per cluster to get a more granular cluster\n",
    "topic_model_2 = new_model(min_cluster_size=10)\n",
    "topics, probs = topic_model_2.fit_transform(docs, embeddings)\n",
    "fraction_of_answers_visulaized = 0.10\n",
    "topic_model_2.visualize_documents(docs, reduced_embeddings=data[\"2D_embeddings\"][:number_of_reviews], sample=fraction_of_answers_visulaized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_class  = topic_model.topics_per_class(docs, reviews_df['rating'])\n",
    "topic_model.visualize_topics_per_class(topics_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cherry on top - Topics over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every review, we have the date it was published on.\n",
    "reviews_df[\"published_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df[\"published_date\"] = pd.to_datetime(reviews_df[\"published_date\"], utc=True)\n",
    "reviews_df[\"published_date\"] = reviews_df[\"published_date\"].dt.to_period('Q').dt.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_interesting_topics = [0, 8, 9]\n",
    "topics_over_time = topic_model.topics_over_time(docs, reviews_df[\"published_date\"])\n",
    "topic_model.visualize_topics_over_time(topics_over_time, topics=list_of_interesting_topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
